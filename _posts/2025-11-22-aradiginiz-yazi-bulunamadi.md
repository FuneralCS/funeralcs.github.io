---
title: "AradÄ±ÄŸÄ±nÄ±z 'FuneralCS yazÄ±sÄ±' ile ilgili hiÃ§bir arama sonucu mevcut deÄŸil"
date: 2025-11-22 9:00:00 +0300
categories: [teknoloji, internet, bilgi teorisi, yapay zeka, makine ogrenmesi, matematik]
tags: [retrieval, embedding, pagerank, bert, limit dataset, limit article, limit makale, cross encoders, google, not found, search]
author: tunahan
image:
  path: /assets/img/2025-11-22-aradiginiz-yazi-bulunamadi/cover.webp
  alt: "Google arama ekranÄ±nda 'AradÄ±ÄŸÄ±nÄ±z FuneralCS yazÄ±sÄ± ile ilgili hiÃ§bir arama sonucu mevcut deÄŸil' mesajÄ±"
description: "Google her ÅŸeyi bulabilir mi? DeepMind'Ä±n LIMIT makalesi ile embedding, retrieval ve vektÃ¶r tabanlÄ± aramalarÄ±n matematiksel sÄ±nÄ±rlarÄ±nÄ± Python Ã¶rnekleriyle inceliyoruz."
toc: true
math: true
mermaid: false
comments: true
pin: false
lang: tr
---
# AradÄ±ÄŸÄ±nÄ±z YazÄ± BulunamadÄ±: Google'Ä±n GÃ¶remediÄŸi Yerler

> UyarÄ±: Bu yazÄ± aslÄ±nda o aradÄ±ÄŸÄ±nÄ±z yazÄ± ama arattÄ±ÄŸÄ±nÄ±zda, karÅŸÄ±nÄ±za yine â€œAradÄ±ÄŸÄ±nÄ±z 'FuneralCS yazÄ±sÄ±' ile ilgili hiÃ§bir arama sonucu mevcut deÄŸil.â€ Ã§Ä±kacak. Ve o sonuÃ§, iÅŸte ÅŸu an okuduÄŸunuz yazÄ±nÄ±n ta kendisi; yani bulamadÄ±ÄŸÄ±nÄ±z bir ÅŸeyi okuyacaksÄ±nÄ±z...
{: .prompt-warning}

> EditÃ¶r Notu: Bu yazÄ± ilerledikÃ§e giderek daha teknik bir yapÄ±ya bÃ¼rÃ¼nmektedir. Ä°lk bÃ¶lÃ¼mler herkesin rahatlÄ±kla takip edebileceÄŸi ÅŸekilde sadeleÅŸtirilmiÅŸ; ilerleyen kÄ±sÄ±mlarda ise makine Ã¶ÄŸrenmesi, embedding ve retrieval gibi daha teknik konulara girilmiÅŸtir. EÄŸer yalnÄ±zca genel fikir edinmek istiyorsanÄ±z giriÅŸ ve ilk bÃ¶lÃ¼mler yeterli olacaktÄ±r.
{: .prompt-warning}

HiÃ§ Google'da aradÄ±ÄŸÄ±nÄ±z ÅŸeyi bulamadÄ±ÄŸÄ±nÄ±z oldu mu? SÄ±ralamada gerilerde olmasÄ±ndan bahsetmiyorum. Hani ÅŸu ekran var ya, iÅŸte bugÃ¼nÃ¼n konusu tam olarak bu ekranÄ±n teknik ve matematiksel sebebi:

<figure>

<img src="assets/img/2025-11-22-aradiginiz-yazi-bulunamadi/bulunamadÄ±.webp" alt="Google SonuÃ§ BulunamadÄ± EkranÄ±" width="600">

<figcaption>Google'Ä±n o meÅŸhur "Ã§aresiz" balÄ±kÃ§Ä±sÄ±.</figcaption>

</figure>

## PageRank: Her Åeyin BaÅŸlangÄ±cÄ±

Larry Page ve Sergey Brin, doktora yaptÄ±klarÄ± sÄ±rada â€œdÃ¼nyadaki bilgiyi organize etmek ve evrensel olarak eriÅŸilebilir hale getirmekâ€ gibi devasa bir hedefle Google'Ä± kurdu. Ä°lk kurguladÄ±klarÄ± algoritma aslÄ±nda oldukÃ§a basitti; **Googlebot** (web crawler) Ã¶nce bilinen bÃ¼yÃ¼k sitelerden baÅŸlar, sayfalarÄ± indirir, iÃ§indeki linkleri Ã§Ä±karÄ±r ve bu dÃ¶ngÃ¼yÃ¼ sonsuza kadar tekrarlar.

> MeraklÄ±sÄ±na: Peki bu kadar bÃ¼yÃ¼k bir aÄŸÄ± taramak Ã§ok uzun sÃ¼rmez mi? Bir haber sayfasÄ± yeni iÃ§erik girdiÄŸinde neden neredeyse anÄ±nda arama sonuÃ§larÄ±nda gÃ¶rebiliyoruz? Buraya birazdan, modern yÃ¶ntemlere geÃ§tiÄŸimizde dÃ¶neceÄŸiz.
> 
{: .prompt-info }

SÄ±ralama kÄ±smÄ±nda ise efsanevi **PageRank** devreye giriyordu. Akademik dÃ¼nyada bir makalenin deÄŸeri nasÄ±l aldÄ±ÄŸÄ± atÄ±flarla Ã¶lÃ§Ã¼lÃ¼yorsa; Google da aynÄ± mantÄ±ÄŸÄ± web sitelerine uyguladÄ±. Bir sayfa baÅŸka sitelerden ne kadar Ã§ok link alÄ±yorsa, arama sonuÃ§larÄ±nda o kadar deÄŸerli sayÄ±lÄ±yordu. Ãœstelik popÃ¼ler sitelerden gelen linkler, sÄ±radan sitelerden gelenlerden daha "aÄŸÄ±r" basÄ±yordu.

Ancak bu sistemin ciddi dezavantajlarÄ± vardÄ±:

- **HiÃ§ link almayan siteler** iÃ§erikleri ne kadar iyi olursa olsun neredeyse gÃ¶rÃ¼nmez kalÄ±yordu.
    
- **ManipÃ¼lasyona Ã§ok aÃ§Ä±ktÄ±**; link satÄ±n alarak sÄ±ralama ÅŸiÅŸirilebiliyordu veya Ã§ok basit teknikler vardÄ± (Wikipedia'da herhangi bir yazÄ±da kendi sitenize atÄ±f yapmak gibi).
    
- **Tazelik (Freshness) ve Konu SapmasÄ± (Topic Bias)** sorunlarÄ± nedeniyle gÃ¼ncel veya Ã§ok niÅŸ iÃ§erikler geri planda kalabiliyordu.
    

Google bu yÃ¼zden zamanla PageRank'in yanÄ±na yÃ¼zlerce farklÄ± `sinyal` eklemek zorunda kaldÄ±.

---

<figure>

<img src="assets/img/2025-11-22-aradiginiz-yazi-bulunamadi/pagerank.gif" alt="Pagerank Ã§alÄ±ÅŸma mantÄ±ÄŸÄ±" width="700">

<figcaption>PageRank algoritmasÄ±nda atÄ±flarÄ±n site Ã¶lÃ§eÄŸine gÃ¶re etkisi.</figcaption>

</figure>

Åu anki sistem ise Ã§ok daha akÄ±llÄ± ve AI araÃ§larÄ±nÄ± da yoÄŸun bir ÅŸekilde kullanÄ±yor. Haber siteleri gibi anlÄ±k gÃ¼ncellenmesi gereken siteleri crawler araÃ§lar belki de her saniye tekrar tekrar tarÄ±yor ve dizini gÃ¼ncelliyor.

> ArtÄ±k sadece link deÄŸil; iÃ§erik kalitesi, gÃ¼ncellik, gÃ¼venilirlik, spam kontrolÃ¼, kullanÄ±cÄ± niyeti ve daha pek Ã§ok parametreyi kullanÄ±yor Google.
> 
{: .prompt-info }

`RankBrain`, `BERT`, `MUM`, `neural matching` ve daha pek Ã§oÄŸu... Bu terimlerin hepsi, kaynakÃ§ada da yer verdiÄŸim "Google Arama sÄ±ralama sistemleri kÄ±lavuzu" iÃ§erisinde mevcut. Ama biz bu yazÄ±da orada yer alan "BERT" ve tÃ¼revlerinin her ÅŸeyi nasÄ±l **"temsil edemediÄŸine"** deÄŸineceÄŸiz.

## LIMIT: Google'Ä±n Kendi MÃ¼hendislerinden Ä°tiraf

Konuyla ilgili incelediÄŸimiz makale, bizzat Google DeepMind ekibinden (baÅŸ yazar Orion Weller) Ã§Ä±kÄ±yor. Yani Google'Ä±n arama motoru paradigmasÄ±nÄ±n sÄ±nÄ±rlarÄ±nÄ± Ã§izen makale, yine iÃ§eriden geliyor. Ã‡alÄ±ÅŸmanÄ±n adÄ± manidar: **LIMIT**.

Yazarlar, Ã§ok basit bir soru soruyor: "Bir yapay zeka modeli, kelimeleri sayÄ±lara (vektÃ¶rlere) dÃ¶nÃ¼ÅŸtÃ¼rÃ¼rken neleri kaybeder?".
YazÄ±, vektÃ¶rlerin temsil yeteneÄŸini anlatarak baÅŸlÄ±yor. ArdÄ±ndan eski Ã§alÄ±ÅŸmalar ile bazÄ± ÅŸeylerin neden temsil edilemediÄŸini gÃ¶steriyor.

Bu makalenin en Ã§arpÄ±cÄ± yanÄ± ise ÅŸu: Ä°lkokuldaki okumayÄ± Ã¶ÄŸreten fiÅŸlerdeki basit cÃ¼mlelerle bile, devasa _embedding_ sistemlerinin nasÄ±l Ã§Ä±kmaza girebildiÄŸini kanÄ±tlÄ±yor. Ãœstelik Ã§alÄ±ÅŸma Ã§ok kÃ¼Ã§Ã¼k sÄ±ralama deÄŸerleriyle yapÄ±lmÄ±ÅŸ, yani modelden yalnÄ±zca 2 tane cÃ¼mleyi doÄŸru sÄ±ralamasÄ± isteniyor.

<figure>

<img src="assets/img/2025-11-22-aradiginiz-yazi-bulunamadi/limit.webp" alt="LIMIT Dataseti" width="600">

<figcaption>LIMIT Dataseti: Kim neyi seviyor?</figcaption>

</figure>
> Ufak bir bilgi: Quokka, Avustralya'da yaÅŸayan kÄ±sa kuyruklu bir kanguru tÃ¼rÃ¼ymÃ¼ÅŸ. FotoÄŸraflarda hep gÃ¼lÃ¼yormuÅŸ gibi Ã§Ä±karlar, oradan hatÄ±rlarsÄ±nÄ±z. ğŸ˜…
> 
{: .prompt-tip }

**Ã–ncelikle embedding kavramÄ±na Ã§ok kÄ±sa deÄŸinelim.**

Bilgisayar her ÅŸeyi sayÄ±larla anlar. DolayÄ±sÄ±yla bir ÅŸeyi bilgisayara Ã¶ÄŸretmek iÃ§in, onu sayÄ±larla temsil etmek gerekir.

Mesela Ã§ok basit bir yÃ¶ntem dÃ¼ÅŸÃ¼nelim: elma = 1, armut = 2, araba = 3.

Bu ÅŸekilde etiketlersek, bilgisayar â€œarmut > elmaâ€ (2 > 1) gibi anlamsÄ±z bir matematiksel bÃ¼yÃ¼klÃ¼k karÅŸÄ±laÅŸtÄ±rmasÄ± yapabilir. Ya da 1â€“2â€“3 ardÄ±ÅŸÄ±klÄ±ÄŸÄ± yÃ¼zÃ¼nden, â€œaraba da meyvelerin bir benzeri galibaâ€ sonucunu Ã§Ä±karabilir Ã§Ã¼nkÃ¼ sayÄ±sal uzayda yan yanalar. Yani bu temsil hiÃ§bir gerÃ§ek anlam taÅŸÄ±mÄ±yor (bkz. "Label Encoding").

Ä°ÅŸte **Embedding** bu yÃ¼zden tek boyutlu etiketlerden ibaret olamaz. Bunun yerine Ã§ok boyutlu uzaylar kullanÄ±yoruz. Her kelime veya nesne, Ã§ok boyutlu bir **vektÃ¶r** (veya tensÃ¶r) ile temsil ediliyor. Her boyut, nesnenin farklÄ± bir Ã¶zelliÄŸini (feature) yansÄ±tÄ±yor. BÃ¶ylece â€œelmaâ€ ile â€œarmutâ€ uzayda birbirine yakÄ±n konumlanÄ±rken, â€œarabaâ€ bambaÅŸka bir koordinatta durabiliyor.

<figure>
<img src="assets/img/2025-11-22-aradiginiz-yazi-bulunamadi/embed_space.webp" alt="Embedding uzayÄ± hakkÄ±nda gÃ¶rselleÅŸtirme " width="600">
<figcaption>Embedding uzayÄ± hakkÄ±nda gÃ¶rselleÅŸtirme</figcaption>
</figure>

Peki Ã¶yle ÅŸeyler var mÄ±dÄ±r ki hiÃ§bir ÅŸekilde matematik ile temsil edilemez veya ayrÄ±ÅŸtÄ±rÄ±lamaz? Mesela yukarÄ±daki Quokka gÃ¶rselindeki mantÄ±ÄŸÄ± bilgisayar ne kadar iyi ayÄ±rt edebilecek? Gelin, bir metni "gÃ¶mmeyi" (embedding) deneyelim.

Ã–rneÄŸin bu yazÄ±mÄ±zÄ±n baÅŸlÄ±ÄŸÄ±nÄ± sizler iÃ§in "SBERT" ile gÃ¶mmeyi deneyeceÄŸim. Basit bir kod ile baÅŸlayalÄ±m:

> Kod geliyor! ğŸ˜… Merak etmeyin, anlamak iÃ§in uzman olmanÄ±z gerekmiyor; biraz yazÄ±lÄ±m okuryazarlÄ±ÄŸÄ± iÅŸinizi gÃ¶recektir. Gerekli yerlere aÃ§Ä±klama bÄ±raktÄ±m.

```python
from sentence_transformers import SentenceTransformer

model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2') 
# Bunu Google sorgusunu bilgisayara anlatan tercÃ¼man/dÃ¶nÃ¼ÅŸtÃ¼rÃ¼cÃ¼ gibi dÃ¼ÅŸÃ¼nebiliriz.

text = "AradÄ±ÄŸÄ±nÄ±z 'FuneralCS yazÄ±sÄ±' ile ilgili hiÃ§bir arama sonucu mevcut deÄŸil" 
# Bu ise Google'a olan sorumuz.

embedding = model.encode(text)
print("VektÃ¶rÃ¼n boyutu:", len(embedding))

print("Ä°lk 10 deÄŸer:", embedding[:10])

# Ã‡IKTI:
# VektÃ¶rÃ¼n boyutu: 768 
# (TÃ¼m cÃ¼mlenin bilgisayar iÃ§in ifade ettiÄŸi anlam uzunluÄŸu - bunu biz belirledik aslÄ±nda)
# Ä°lk 10 deÄŸer: [ 0.08241844 -0.00802192 -0.00111354  0.03817566 -0.0503126   0.00824948
#   0.04679048  0.01312113  0.01456734  0.01648803] 
```

Peki cÃ¼mleyi birazcÄ±k deÄŸiÅŸtirip ÅŸÃ¶yle yapalÄ±m:

```python
text = "AradÄ±ÄŸÄ±nÄ±z  'YazÄ±' ile ilgili hiÃ§bir arama sonucu mevcut deÄŸil"
embedding2 = model.encode(text)

# VektÃ¶rÃ¼n boyutu: 768
# Ä°lk 10 deÄŸer: [ 0.03601046 -0.01979215 -0.01988745 -0.00076254 -0.03193635  0.03404633
#   0.0785526   0.01048531  0.02877098  0.01428796]

# Åimdi de Cosine Similarity hesaplayalÄ±m (vektÃ¶rler arasÄ±ndaki aÃ§Ä±nÄ±n kosinÃ¼s deÄŸeri):
import torch
from torch.nn.functional import cosine_similarity

embedding = torch.tensor(embedding, dtype=torch.float32).unsqueeze(0) 
# KosinÃ¼s hesaplamak iÃ§in vektÃ¶rÃ¼ tensÃ¶rlere Ã§evirmeliyiz, bu kÄ±sÄ±mlar saf matematik.

embedding2 = torch.tensor(embedding2, dtype=torch.float32).unsqueeze(0)

print(cosine_similarity(embedding, embedding2))

# Ã‡IKTI:
# tensor([0.7448])
```

Yani bilgisayar bu iki cÃ¼mleyi **%74.48** benzer buldu.

Peki ÅŸÃ¶yle yaparsak ne olur?

```python
text = "AradÄ±ÄŸÄ±nÄ±z 'FuneralCS' ile ilgili hiÃ§bir arama sonucu mevcut deÄŸil"
embedding3 = model.encode(text)

# VektÃ¶rÃ¼n boyutu: 768
# Ä°lk 10 deÄŸer: [ 0.0866233  -0.01295199 -0.0074097   0.03779288 -0.05800581  0.00488742
#   0.05130353  0.01200954  0.02305291  0.01696091]

print(cosine_similarity(embedding, embedding3))

# Ã‡IKTI:
# tensor([0.9841])
```

GÃ¶rdÃ¼ÄŸÃ¼mÃ¼z Ã¼zere %98.41 benzer Ã§Ä±ktÄ±.

Ama biz sorgulardan birinde siteyi (FuneralCS), birinde ise sitenin iÃ§indeki yazÄ±yÄ± aradÄ±k. Aradaki fark bizim iÃ§in bÃ¼yÃ¼k ama bilgisayar iÃ§in neredeyse yok hÃ¼kmÃ¼nde.

LIMIT dataseti de tam olarak bu soruna odaklanÄ±yor. Belirli bir $n$ boyutu iÃ§in (Ã¶rneÄŸin 768 boyutlu bir vektÃ¶r), %100 doÄŸruluk ile temsil edilebilecek (yani hatasÄ±z sÄ±ralanabilecek) dokÃ¼man sayÄ±sÄ± kaÃ§tÄ±r?

Tamam, belki bizim 3 cÃ¼mlemiz arasÄ±ndan bir sorgu vektÃ¶rÃ¼ ile sÄ±ralama yapmak kolay ancak Google milyarlarca varyasyonun olduÄŸu bir veri kÃ¼mesinden "retrieval" (geri getirme) yapÄ±yor.

> Retrieval: Bilgisayar biliminde â€œgeri getirme / bulup Ã§Ä±karmaâ€ demektir. Yani bir veritabanÄ±ndan, kullanÄ±cÄ±nÄ±n sorgusuna en uygun vektÃ¶rÃ¼n bulunup sunulmasÄ± iÅŸlemidir.
> 
{: .prompt-info }

YukarÄ±da da gÃ¶rdÃ¼ÄŸÃ¼mÃ¼z Ã¼zere benzer gÃ¶rÃ¼nen cÃ¼mleler bazen %74 Ã§Ä±kÄ±yor, bazen %98; ama bu farkÄ±n ne zaman kritik olduÄŸu asÄ±l bÃ¼yÃ¼k soru.

Makalede denenen modellerin hepsi son teknoloji (SoTA - State of Art) modeller. Ã‡alÄ±ÅŸma **learning theory** ve **communication complexity** temellerine dayanÄ±yor.

> Learning theory (Ã¶ÄŸrenme sÃ¼reÃ§lerini matematiksel olarak inceleyen alan) ve communication complexity ise bir problemi Ã§Ã¶zmek iÃ§in sistemler arasÄ± gereken bilgi alÄ±ÅŸveriÅŸinin Ã¶lÃ§Ã¼mÃ¼dÃ¼r.
> 
{: .prompt-info }

<figure>

<img src="assets/img/2025-11-22-aradiginiz-yazi-bulunamadi/recall.webp" alt="Modellerin Recall SkorlarÄ±" width="600">

<figcaption>Modelin boyutunun sÄ±nÄ±rlayÄ±cÄ± bir faktÃ¶r olduÄŸunu ve boyut arttÄ±kÃ§a performansÄ±n da arttÄ±ÄŸÄ±nÄ± gÃ¶rÃ¼yoruz. Ancak Ã§ok vektÃ¶rlÃ¼ modellerin bile zorlandÄ±ÄŸÄ±nÄ± gÃ¶rÃ¼yoruz.</figcaption>

</figure>

> **BurayÄ± biraz detaylÄ± aÃ§Ä±klamam iyi olacaktÄ±r: Recall (Geri Ã‡aÄŸÄ±rma)**
> 
> Bilgi getirme (information retrieval) sistemlerinde performansÄ± Ã¶lÃ§mek iÃ§in kullanÄ±lan en temel metriklerden biridir.
> 
> - **Recall** = Sistemin â€œilgiliâ€ dokÃ¼manlarÄ±n kaÃ§Ä±nÄ± bulabildiÄŸi.
>     
> - **@k** = Ä°lk _k_ sonuÃ§ iÃ§inde.
>     
> 
> Diyelim ki sorgun var: **â€œFuneralCS yazÄ±sÄ±â€**
> 
> - GerÃ§ekte bu sorguyla alakalÄ± veritabanÄ±nda **3 dokÃ¼man** var.
>     
> - Sistem sana bir sÄ±ralama dÃ¶ndÃ¼rdÃ¼: `[Dok1, Dok2, Dok3, Dok4, Dok5 â€¦]`
>     
> 
> Åimdi senaryoya bakalÄ±m:
> 
> - EÄŸer ilk 2 sonuÃ§ **[Dok1, Dok4]** ise â†’ AlakalÄ± 3 dokÃ¼mandan sadece **1 tanesi** ilk 2'ye girmiÅŸ.
>     
>     - Recall@2 = 1/3 â‰ˆ **0.33** -> %33 BaÅŸarÄ±.
>         
> - EÄŸer ilk 2 sonuÃ§ **[Dok1, Dok2]** ise â†’ AlakalÄ± dokÃ¼manlardan **2 tanesi** ilk 2'de.
>     
>     - Recall@2 = 2/3 â‰ˆ 0.66 -> %66 BaÅŸarÄ±.
>         
>         {: .prompt-info }
>         

GÃ¶rdÃ¼ÄŸÃ¼mÃ¼z Ã¼zere sonuÃ§lar Ã§ok ÅŸaÅŸÄ±rtÄ±cÄ±. GÃ¶rev son derece basit olmasÄ±na raÄŸmen (Quokka'nÄ±n sevdiÄŸi yiyecekler) devasa modeller zorluklar yaÅŸÄ±yor. Bu aÃ§Ä±kÃ§a ÅŸu anlama geliyor: GÃ¶mmeler (embeddings) Ã§ok sayÄ±da kombinasyonu temsil edebilir, ancak **tÃ¼m** kombinasyonlarÄ± temsil edemez veya en azÄ±ndan belirli bir $k$ deÄŸerinde Ã§aÄŸÄ±rÄ±labileceÄŸini garanti edemez.

## Alternatif Teknikler ve Mimariler

Peki bu iÅŸin Ã§Ã¶zÃ¼mÃ¼ yok mu? AraÅŸtÄ±rmacÄ±lar alternatiflere de bakmÄ±ÅŸlar:

<figure>

<img src="assets/img/2025-11-22-aradiginiz-yazi-bulunamadi/encoder_diff.webp" alt="Encoder'larÄ±n farklarÄ±" width="600">

<figcaption>Encoder'larÄ±n farklarÄ±</figcaption>

</figure>

### 1. Cross-Encoders (Ã‡apraz KodlayÄ±cÄ±lar)

- Normalde â€œilk aÅŸama retrievalâ€ (milyonlarca dokÃ¼mandan birkaÃ§ yÃ¼z aday seÃ§me) iÃ§in uygun deÄŸillerdir. Ã‡Ã¼nkÃ¼ **Ã§ok pahalÄ±dÄ±r** (hesaplama maliyeti Ã§ok yÃ¼ksek).
    
- Genellikle â€œrerankingâ€ (ilk aÅŸamadan gelen 100 adayÄ± tekrar, daha hassas sÄ±ralamak) iÃ§in kullanÄ±lÄ±rlar.
    
- LIMIT dataseti Ã¼zerinde **Gemini-2.5-Pro** denenmiÅŸ:
    
    - Ona **tÃ¼m 46 dokÃ¼man + 1000 query** tek seferde verilmiÅŸ.
        
    - %100 baÅŸarÄ±yla doÄŸru eÅŸleÅŸmeleri bulmuÅŸ (ilgili makalenin `Cross-Encoders` kÄ±smÄ±nda bulabilirsiniz).
        
- Yani LIMIT dataseti, embedding modelleri iÃ§in bir kabus olsa da, cross-encoder iÃ§in â€œÃ§ocuk oyuncaÄŸÄ±â€. Ama maliyet ve hÄ±z yÃ¼zÃ¼nden tÃ¼m Google aramalarÄ±nda en baÅŸta kullanÄ±lamaz.

### 2. Multi-vector Modeller

- Normal embedding modellerinde â†’ DokÃ¼man **tek bir vektÃ¶rle** temsil edilir.
    
- Multi-vector modellerde â†’ Her dokÃ¼man **birden fazla vektÃ¶r** ile temsil edilir (Ã¶rneÄŸin ColBERT).
    

**Ã–rnek:**

- **DokÃ¼man:** _â€œkÄ±rmÄ±zÄ± renkli bir araba gÃ¶rdÃ¼mâ€_
    
- **Sorgu:** _â€œkÄ±rmÄ±zÄ± renkâ€_
    
    - â€œkÄ±rmÄ±zÄ±â€ (sorgu) â†” â€œkÄ±rmÄ±zÄ±â€ (dokÃ¼man) = 1/5
        
    - â€œrenkâ€ (sorgu) â†” â€œrenkliâ€ (dokÃ¼man) â‰ˆ 0.8/5
        
    - Toplam skor â‰ˆ 1.8/5
        

Bu yÃ¶ntem sayesinde, SBERT gibi tek vektÃ¶rlÃ¼ modellerde kaybolan "kÄ±rmÄ±zÄ± renkli" ayrÄ±mÄ± korunmuÅŸ olur.

### 3. Sparse (Seyrek) Modeller

- BM25 gibi â€œklasikâ€ yÃ¶ntemler aslÄ±nda dense modellerin aksine **Ã§ok yÃ¼ksek boyutlu vektÃ¶rler** kullanÄ±r (her kelime = bir boyut).
    
- Her kelime bir boyuttur â†’ VektÃ¶rÃ¼n boyutu = BÃ¼tÃ¼n kelime haznesi (milyonlarca olabilir).
    
- Sorgu ve dokÃ¼man = Kelime frekanslarÄ±na gÃ¶re sparse (Ã§oÄŸu deÄŸer 0'dÄ±r).
    
- Skor = Kelime Ã¶rtÃ¼ÅŸmesine gÃ¶re hesaplanÄ±r (TF-IDF tÃ¼revi).
    
- Bir de bunun nÃ¶ral aÄŸlardaki hali vardÄ±r (SPLADE vb.).
    
- Ã‡ok bÃ¼yÃ¼k olduÄŸu iÃ§in teorik embedding limitlerine takÄ±lmÄ±yor gibi gÃ¶rÃ¼nÃ¼r ama **anlam eÅŸlemesi** zayÄ±ftÄ±r (EÅŸ seslileri karÄ±ÅŸtÄ±ran TF-IDF yapÄ±sÄ±na benzer).
    

<figure>

<img src="assets/img/2025-11-22-aradiginiz-yazi-bulunamadi/critical.webp" alt="Boyut baÅŸÄ±na doÄŸruluk sÄ±nÄ±rlarÄ±" width="600">

<figcaption>Boyut baÅŸÄ±na doÄŸruluk sÄ±nÄ±rlarÄ±: Kritik N NoktasÄ±.</figcaption>

</figure>

## Peki Google Bu YazÄ±yÄ± Bulabilecek mi?

Bulamayabilir. Ã‡Ã¼nkÃ¼ araÅŸtÄ±rmacÄ±lar her embedding boyutu (d) iÃ§in bir â€œkritik n noktasÄ±â€ tanÄ±mlÄ±yor.

Bu nokta, modelin tÃ¼m kombinasyonlarÄ± doÄŸru temsil edemeyeceÄŸi dokÃ¼man sayÄ±sÄ±nÄ± gÃ¶steriyor.

BaÅŸka bir deyiÅŸle: Boyut ne kadar kÃ¼Ã§Ã¼kse, modelin â€œayÄ±rt edebileceÄŸiâ€ dokÃ¼man sayÄ±sÄ± da o kadar sÄ±nÄ±rlÄ±.

Ã–rneÄŸin:

- **d = 512** â†’ yaklaÅŸÄ±k **500 bin** dokÃ¼man
    
- **d = 768** â†’ **1.7 milyon** dokÃ¼man
    
- **d = 1024** â†’ **4 milyon** dokÃ¼man
    
- **d = 3072** â†’ **107 milyon** dokÃ¼man
    
- **d = 4096** â†’ **250 milyon** dokÃ¼man
    

Bu iliÅŸkiyi ÅŸÃ¶yle bir polinom fonksiyonla modellemiÅŸler ($y$ burada aÃ§Ä±klanabilir dokÃ¼man sayÄ±sÄ±dÄ±r):

$$y = -10.5322 + 4.0309d + 0.0520d^2 + 0.0037d^3 $$
> Yani boyut (**d**) bÃ¼yÃ¼dÃ¼kÃ§e ayÄ±rt edilebilecek dokÃ¼man sayÄ±sÄ± hÄ±zla artÄ±yor. 
> Ama unutmayalÄ±m: Bu hesap **ideal koÅŸullar** iÃ§in geÃ§erli. Yani modelin doÄŸrudan test setine optimize edilip dil kÄ±sÄ±tlarÄ± olmadan Ã§alÄ±ÅŸtÄ±ÄŸÄ± â€œfree embeddingâ€ durumu. 
> **GerÃ§ek dÃ¼nyadaki dil modelleri**, doÄŸal dilin karmaÅŸÄ±klÄ±ÄŸÄ± nedeniyle bu sÄ±nÄ±rlarÄ±n Ã§ok altÄ±nda performans gÃ¶steriyor. {: .prompt-info } 

KiÅŸisel fikrim ÅŸu ki; bugÃ¼n Google bazÄ± yazÄ±larÄ± bulamÄ±yor olabilir. Ama **multi-vector** modeller ve hibrit sistemler, gelecekte bu yazÄ±nÄ±n bile Googleâ€™da kolayca bulunabilmesini mÃ¼mkÃ¼n kÄ±lacak. 

Ancak ÅŸu haliyle Google'Ä±n dizinindeki dokÃ¼man sayÄ±sÄ±nÄ± (gezegen boyutunda) dÃ¼ÅŸÃ¼nÃ¼rsek iÅŸimiz biraz zor gibi. Yani belki de bu yazÄ±, gerÃ§ekten Google'Ä±n bulamayacaÄŸÄ± bir yazÄ±dÄ±r. Ama siz buldunuz. Belki bir baÅŸkasÄ±nÄ±n bulmasÄ±na da yardÄ±mcÄ± olursunuz. 

> Merak edenler iÃ§in tÃ¼m kodu Ã§alÄ±ÅŸtÄ±rabileceÄŸiniz bir Colab dosyasÄ± hazÄ±rladÄ±m: [Colab Notebook](https://colab.research.google.com/drive/1tATUQ6eIwMF1CVHe32dcmqYKgYOXfcMJ?usp=sharing) 
{: .prompt-tip } 
### KaynakÃ§a ve Ä°leri Okuma 
1. [PageRank Ã–rneÄŸi â€“ Wikipedia][1]
2. [Google Arama SÄ±ralama Sistemleri KÄ±lavuzu][2]
3. [On the Theoretical Limitations of Embedding-Based Retrieval][3]

[1]: https://en.wikipedia.org/wiki/PageRank#/media/File:Page_rank_animation.gif
[2]: https://developers.google.com/search/docs/appearance/ranking-systems-guide?hl=tr
[3]: https://doi.org/10.48550/arXiv.2508.21038
